WEBVTT FILE

1
00:07.400 --> 00:08.400
大家好

2
00:08.400 --> 00:09.150
我叫Sacha Guddoy

3
00:09.150 --> 00:12.100
是Grabyo的首席前端工程师

slide-2
00:12.100 --> 00:15.170
Grabyo是一个SaaS平台

5
00:15.170 --> 00:19.280
向商业广播公司提供直播制作工具

6-p
00:19.280 --> 00:22.470
我们的一些服务包括直播制作

7
00:22.470 --> 00:25.450
视频编辑 从直播流中剪辑

8
00:25.450 --> 00:28.203
以及发布到各种终端

slide-3
00:30.490 --> 00:34.630
我们在Grabyo提供的直播制作服务中使用了WebRTC

10-p
00:35.100 --> 00:37.910
其工作方式是 用户会看到

11
00:37.910 --> 00:38.880
在他们的web浏览器中

12
00:38.880 --> 00:41.650
会显示多个直播流输入

13
00:41.650 --> 00:44.810
他们能够监控这些直播流

14
00:44.810 --> 00:47.976
并选择哪些流输出至

15
00:47.976 --> 00:50.363
他们的广播终端

16-p
00:52.150 --> 00:54.750
我们也有多个Sidecar模式应用

17
00:54.750 --> 00:56.240
和多窗口的工作流

18
00:56.240 --> 00:58.720
例如 弹出一个播放器

slide-4
00:58.720 --> 01:00.440
我们面临的一个挑战

20
01:00.440 --> 01:02.310
就是直播流的同步

21-p
01:02.310 --> 01:06.620
我们想做的是同时输入多个

22
01:06.620 --> 01:08.000
来自不同摄像机的直播画面

23
01:08.000 --> 01:10.170
并能在它们之间切换

24
01:10.170 --> 01:12.560
但是 如果我们的直播画面

25
01:12.560 --> 01:13.393
不是完全同步的

26
01:13.393 --> 01:15.180
如果有两台摄像机不是完全同步的

27
01:15.180 --> 01:16.880
当你在它们之间切换时

28
01:16.880 --> 01:18.550
会很明显地发现它们之间有一些延迟

29
01:18.550 --> 01:21.730
这对观众来说是难以忍受的

30-p
01:21.730 --> 01:24.960
当你的页面上有多个WebRTC流时

31
01:24.960 --> 01:27.140
要保持这些流的同步

32
01:27.140 --> 01:29.810
没有那么简单

33
01:29.810 --> 01:33.833
浏览器会尽力而为 但这些流并未绑定

34-p
01:35.490 --> 01:36.323
举例来说

35
01:36.323 --> 01:40.260
如果你在不同的摄像头之间切换

36
01:40.260 --> 01:43.850
你希望这些摄像头的画面

37
01:43.850 --> 01:45.410
能完全在同一时间显示

38
01:45.410 --> 01:48.930
如果你要进行多人聊天 你不希望有延迟

slide-5
01:48.930 --> 01:51.600
同步方面是相当困难的

40
01:51.600 --> 01:53.700
网络条件可能难以预测

41
01:55.280 --> 01:58.000
你没有办法纠正这一点

42
01:58.000 --> 02:00.750
也没有办法与客户端的流同步

43
02:00.750 --> 02:01.700
进行协调

44-p
02:02.760 --> 02:05.420
如果在数据流上有嵌入式的时间戳

45
02:05.420 --> 02:07.970
那么你就有可能做到这一点

46
02:07.970 --> 02:10.870
使用较底层的技术 如WebTransport

47
02:10.870 --> 02:12.140
可能会助你实现这一点

48
02:12.140 --> 02:15.990
甚至与WebRTC相比

49
02:15.990 --> 02:18.263
这种技术可能更适合这种用例

slide-6
02:19.620 --> 02:22.400
我们最近一直在使用的一种模式

51
02:22.400 --> 02:25.900
是将工作流程分割成不同的浏览器上下文

52
02:25.900 --> 02:29.220
能够创建一个弹出式窗口

53
02:29.220 --> 02:31.150
允许你在一个窗口中监控

54
02:31.150 --> 02:34.850
某个特定的视频

55
02:34.850 --> 02:38.370
并能够在另一个窗口中监控其他一切

56-p
02:38.370 --> 02:40.750
或者能够在一个窗口中编辑你的音频

57
02:40.750 --> 02:42.850
同时在另一个窗口中监控你的视频

58
02:43.750 --> 02:47.300
在最后一种场景中 你将在浏览器中

59
02:47.300 --> 02:49.500
拥有同一个WebRTC连接的

60
02:49.500 --> 02:51.260
两个实例

61
02:51.260 --> 02:54.380
如果我想在一个窗口中看到直播视频流

62
02:54.380 --> 02:58.000
因为那是我的视频控制套件

63
02:58.000 --> 03:01.710
同时我想在另一个窗口看到同样的视频流

64
03:01.710 --> 03:03.860
因为那是我的音频控制套件

65
03:03.860 --> 03:06.200
那么我必须有两个WebRTC连接

66
03:06.200 --> 03:07.940
这是两倍的性能开销

67
03:07.940 --> 03:09.693
两倍的带宽 以此类推

68-p
03:10.870 --> 03:13.880
我们考虑了Shared WebWorkers的工作方式

69
03:13.880 --> 03:16.120
即SharedWorker接口

70
03:16.120 --> 03:20.490
它允许多个上下文共享该Worker中

71
03:20.490 --> 03:22.660
发生的任何事件

72
03:22.660 --> 03:25.570
如果我们能用WebRTC做同样的事情

73
03:25.570 --> 03:28.420
这将大大减少我们的性能开销

74-p
03:30.340 --> 03:32.290
这类工作流对于专业的桌面应用来说

75
03:32.290 --> 03:35.360
真的很强大

76
03:35.360 --> 03:38.500
如果你是使用非线性剪辑软件的视频编辑

77
03:38.500 --> 03:39.880
你可能想要分配尽可能多的屏幕空间

78
03:39.880 --> 03:41.760
给你的时间线 你的显示器

79
03:41.760 --> 03:44.400
你的资源库 等等

80
03:44.400 --> 03:46.980
能够将我们界面各部分分割成不同的窗口

81
03:46.980 --> 03:49.100
以便用户能够

82
03:49.100 --> 03:51.400
按照他们认为合适的方式定位

83
03:51.400 --> 03:52.340
这大有裨益

slide-7
03:53.200 --> 03:55.950
那么这样做有什么好处呢？

85-p
03:55.950 --> 03:57.810
很明显 资源消耗减少了

86
03:57.810 --> 04:00.263
因为你只需要一个连接

87-p
04:01.760 --> 04:04.870
上下文之间有内在的同步性

88
04:04.870 --> 04:08.503
因为数据来自同一个连接

89
04:09.820 --> 04:12.900
现在有可能使用Shared WebWorkers

90
04:12.900 --> 04:14.730
和WebTransport来实现这一点

91
04:14.920 --> 04:17.833
但浏览器对它的支持并不是特别好

92-p
04:18.840 --> 04:21.323
准确性在这项技术中也很重要

93
04:22.640 --> 04:25.580
更准确的时间戳可能有助于我们

94
04:25.580 --> 04:27.450
将这些数据流同步起来

95
04:27.450 --> 04:31.220
而且还有助于同步其他东西

96-p
04:31.220 --> 04:34.840
例如 在DOM中同步显示一个图层

97
04:34.840 --> 04:36.373
或者一条通知

slide-8
04:37.280 --> 04:39.730
对来自WebRTC连接的数据

99
04:39.730 --> 04:42.860
进行编码和解码的能力也会非常有用

100-p
04:42.860 --> 04:44.460
目前WebRTC连接的API接口

101
04:44.460 --> 04:48.200
功能十分有限

102
04:48.200 --> 04:51.593
它无法让我们获取太多有用的信息

103
04:52.890 --> 04:57.217
如果能够把我们自己的代码放在该流程中

104
04:57.217 --> 05:00.200
我们就能够实现所有这些有趣的功能

105-p
05:00.200 --> 05:03.460
比如说 在我们需要的时候

106
05:03.460 --> 05:04.810
展示某帧特定的画面

107
05:04.810 --> 05:07.640
再比如说 从不同的浏览器窗口

108
05:07.640 --> 05:09.840
同步音频和视频

109-p
05:09.840 --> 05:13.480
我们可以在它们被渲染至DOM之前

110
05:13.480 --> 05:15.290
准确地知道正在显示的是哪一帧

111
05:15.290 --> 05:17.780
这样一来我们就可以提前准备DOM元素

112
05:17.780 --> 05:19.880
使其与之同步

113
05:19.880 --> 05:21.470
我们将能够发送

114
05:21.470 --> 05:23.770
专有的纠错数据

115
05:23.770 --> 05:26.350
来修复任何以图像质量为优先的

116
05:26.350 --> 05:28.473
链接故障

117-p
05:29.770 --> 05:31.700
从另一个角度看

118
05:31.700 --> 05:32.800
你可以给人像添加帽饰

119
05:32.800 --> 05:33.810
你可以实现抠像

120
05:33.810 --> 05:35.860
你可以做机器学习分析

121
05:35.860 --> 05:37.410
以及像是背景模糊

122
05:37.410 --> 05:40.240
或者嵌入元数据之类的

123-p
05:40.240 --> 05:42.610
这方面的很多问题

124
05:42.610 --> 05:46.830
都可以用MediaStreamTrack的可插入流功能来解决

125
05:47.200 --> 05:49.100
它目前还只是一项规范草案

126
05:49.950 --> 05:53.393
我真的希望更多的浏览器能支持这一功能

127-p
05:55.810 --> 05:56.643
感谢大家的观看

128
05:56.643 --> 05:58.470
希望我们介绍的用例能带来启发

129
05:58.470 --> 05:59.940
我很期待收到

130
05:59.940 --> 06:02.240
任何问题和反馈

131
06:02.240 --> 06:03.730
谢谢 再见
