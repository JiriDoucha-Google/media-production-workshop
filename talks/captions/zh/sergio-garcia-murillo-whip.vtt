WEBVTT FILE

1
00:07.200 --> 00:09.330
作为非端到端

2
00:09.330 --> 00:11.000
而是点对点的技术

3
00:11.000 --> 00:12.120
以及主要用例是

4
00:12.120 --> 00:13.700
多人会议

5
00:13.700 --> 00:14.870
人们对围绕WebRTC的广播行业

6
00:14.870 --> 00:17.209
一直不太看好

slide-2
00:17.209 --> 00:19.462
它并没有被视作

8
00:19.462 --> 00:21.990
一个可行的

9
00:21.990 --> 00:23.233
流媒体解决方案 因为它不具备扩展性

10
00:23.233 --> 00:24.660
它的传输质量难以保证

11
00:24.660 --> 00:25.720
而且用起来相当不便

slide-3
00:25.720 --> 00:28.760
行业如今实际上由视频点播模式所主导

13
00:30.800 --> 00:31.755
如Netflix Hulu Disney+等

14
00:31.755 --> 00:32.767
甚至不需要实时播放

15-p
00:33.850 --> 00:35.660
然而

16
00:35.660 --> 00:36.560
这场疫情确实改变了这一切

17
00:36.560 --> 00:37.990
它加速了实时媒体

18
00:37.990 --> 00:39.880
工作流的落地

19
00:39.880 --> 00:42.330
最终弥合了网络和广播之间的差距

20-p
00:43.373 --> 00:46.360
实时媒体催生了

21
00:46.360 --> 00:47.193
对接近零延迟互动的需求

22
00:48.640 --> 00:51.350
新的用例使专业级的工作流

23
00:51.350 --> 00:55.500
在消费级设备中成为可能

slide-4
00:55.500 --> 00:57.170
WebRTC是传递这种实时媒体的

25
00:57.170 --> 00:58.830
理想技术

slide-5
00:58.830 --> 01:01.600
它做到了面世时的设计初衷

slide-6
01:01.600 --> 01:03.540
尽管人们对它有一些误解

28
01:03.540 --> 01:05.940
但通过额外属性 如端到端加密

29
01:05.940 --> 01:08.510
或同步广播和SVC支持

30
01:08.510 --> 01:10.980
它仍能在网页上提供广播级高质量媒体

slide-7
01:12.920 --> 01:16.300
然而 由于缺乏标准的通信协议

32
01:16.300 --> 01:19.930
WebRTC无法使用

33
01:19.930 --> 01:22.400
流媒体界日常使用的

34
01:22.400 --> 01:23.800
广泛工具

35
01:23.800 --> 01:26.253
例如OBS FFmpeg和vMix

36-p
01:27.214 --> 01:30.740
更不用说它还缺乏许多专业媒体工作流中

37
01:30.740 --> 01:32.340
广泛可用的硬件编码器和

38
01:32.340 --> 01:34.790
物理输入源

slide-8
01:35.750 --> 01:37.560
在广播行业 RTMP协议

40
01:37.560 --> 01:38.700
广泛用于直播流

41
01:38.700 --> 01:42.600
和向成百上千的媒体平台上载媒体

slide-9
01:43.520 --> 01:45.850
WebRTC在进行实时媒体上载时

43
01:45.850 --> 01:49.180
有很多技术优势 如不增加端到端延迟

44
01:49.180 --> 01:50.310
同时提供更好的网络弹性

45
01:50.310 --> 01:53.343
通过使用SVC编解码器或同步广播

46
01:56.180 --> 01:58.970
复用所需的服务器端处理 选择如VP9或AV1的编解码器

47
01:58.970 --> 02:01.659
端到端的内容如视频内容

48
02:01.659 --> 02:03.840
但通过交付网络进行传输

slide-10
02:03.840 --> 02:06.770
当我们尝试使用WebRTC进行媒体上载时

50
02:06.770 --> 02:09.370
我们意识到虽然WebRTC是实时流媒体的

51
02:09.370 --> 02:12.180
最佳媒体传输协议 但由于缺乏标准协议

52
02:12.180 --> 02:14.700
使得每个WebRTC流媒体服务

53
02:14.700 --> 02:18.550
都需要实现一个自定义的临时协议

54
02:18.550 --> 02:19.910
这使得硬件编码器和广播工具无法采用它

55-p
02:23.380 --> 02:25.350
其他媒体传输协议可用于上载

56
02:25.350 --> 02:28.990
但使用WebRTC进行上载和传输能够让我们

57
02:28.990 --> 02:32.470
在浏览器中本地运行 避免了由于协议转换

58
02:32.470 --> 02:35.130
而增加延迟和实现的复杂性

59
02:35.130 --> 02:38.110
通过设置常见的编解码器

60
02:38.110 --> 02:42.620
以及端到端使用WebRTC功能来避免转码

slide-11
02:42.620 --> 02:43.700
那么解决方案就很简单了

62
02:43.700 --> 02:46.340
我们只需要一个参考通讯协议

63
02:46.340 --> 02:49.950
对这项新协议的需求是 它能够

64
02:49.950 --> 02:51.690
更简单地实现

65
02:51.690 --> 02:56.180
而且在目前的RTMP URI下容易使用

66
02:56.180 --> 02:58.480
支持特定的上载用例

67
02:58.480 --> 03:01.530
这是WebRTC可能用例的

68
03:01.530 --> 03:03.570
一个子集 因为我们

69
03:03.570 --> 03:06.160
只需要支持单向流

70
03:06.160 --> 03:09.300
而且我们不需要支持再协商

71-p
03:09.300 --> 03:12.540
我们需要完全符合WebRTC和RTCWeb的规范

72
03:12.540 --> 03:14.350
但我们必须降低

73
03:14.350 --> 03:17.410
需求和复杂性

74
03:17.410 --> 03:20.400
来重新实现它

75
03:20.400 --> 03:22.393
以便它能被硬件编码器和广播工具采用

slide-12
03:23.460 --> 03:26.511
有一点是清楚的 那就是这个新协议

77
03:26.511 --> 03:27.548
应该尽可能地

78
03:27.548 --> 03:29.100
复用现有的

79
03:29.100 --> 03:30.490
Web技术

80
03:30.490 --> 03:35.490
我们也确实使用了HTTP POST来交换SDP的提议和应答

81
03:35.500 --> 03:37.140
而连接状态是由WebRTC的

82
03:37.140 --> 03:40.900
ICE和DTLS状态控制的

84
03:41.600 --> 03:44.580
认证和授权由大多数SDP Rest接口

85
03:44.580 --> 03:49.800
通过HTTP头部Authorization

86
03:49.800 --> 03:50.563
进行支持

87
03:51.980 --> 03:52.890
此协议的标准制定工作

88
03:52.890 --> 03:56.440
正由互联网工程任务组牵头推进

slide-13
03:56.440 --> 03:58.650
而且已经有一些平台实现了这一协议

90
03:58.650 --> 04:02.340
如Millicast 以及Janus之类的媒体服务器

91
04:02.340 --> 04:06.240
已经支持这一协议 我们也有一些

92
04:06.240 --> 04:07.760
基于GStreamer的客户端实现

93
04:07.760 --> 04:09.480
当然还有基于JavaScript的实现

94-p
04:09.480 --> 04:12.210
我们的目标是能够让硬件编码器实现它

95
04:12.210 --> 04:15.100
并能够在同样支持RTMP协议的工具中

96
04:15.100 --> 04:19.440
使用这一协议

slide-14
04:19.440 --> 04:21.847
这就是在专业媒体流中使用WebRTC的

98
04:21.847 --> 04:25.330
所有需求吗 可惜并非如此

99
04:25.330 --> 04:28.280
这也并不主要是因为缺乏规范

100
04:29.460 --> 04:31.770
而是因为许多所需功能的实现

101
04:31.770 --> 04:35.120
在大多数浏览器中都是滞后的

102
04:35.120 --> 04:36.577
即使有这样的API来启用这些功能

103
04:36.577 --> 04:41.280
大多数时候 它们都处于实验状态

104
04:41.280 --> 04:45.510
隐藏在标记后面 未正式记录或难以发现

105-p
04:45.510 --> 04:46.890
例如 我们在音频方面

106
04:46.890 --> 04:49.960
发现的一些问题

107
04:52.610 --> 04:52.894
是WebRTC…

108
04:54.750 --> 04:58.680
我们可以用Multiopus支持多声道音频

109
04:59.820 --> 05:01.390
Multiopus并不是官方标准

110
05:01.390 --> 05:03.300
它只受Chrome支持

111
05:03.300 --> 05:04.260
而且它是一项隐藏功能

112
05:04.260 --> 05:09.260
需要SDP修改才能支持它

113-p
05:10.640 --> 05:15.300
NetEQ是一项所有WebRTC浏览器中的抖动缓冲器实现

114
05:15.300 --> 05:16.750
它在音乐方面就存在问题 例如

115
05:16.750 --> 05:19.370
Lorenzo就这个话题做了一个很好的演讲

116
05:19.370 --> 05:20.203
其中描述了

117
05:20.203 --> 05:24.380
他在尝试将WebRTC用于音乐时发现的问题

118
05:24.380 --> 05:28.560
所以我建议大家去看一下

119-p
05:28.560 --> 05:31.370
又比如WebRTC和Web Audio之间的整合

120
05:31.370 --> 05:35.640
在Chrome上存在实现的问题

121
05:35.640 --> 05:38.240
当你用WebRTC播放捕获音频时 会增加回声

122
05:40.537 --> 05:43.163
而且谷歌自己也承认了这一点

123-p
05:44.700 --> 05:45.590
另一个例子是

124
05:45.590 --> 05:48.660
WebRTC和WebVTT之间

125
05:48.660 --> 05:50.410
缺乏整合

126
05:50.410 --> 05:54.120
使得实时字幕无法实现

slide-15
05:54.120 --> 05:56.340
同样在视频方面

128
05:56.340 --> 05:58.267
例如 SVC扩展API

129
05:58.267 --> 06:01.100
只能在Chrome中运行

130
06:01.100 --> 06:01.843
而且只是一项实验性功能

131
06:01.843 --> 06:02.676
不过这一情况很可能

132
06:02.676 --> 06:05.140
在接下来的几周内发生变化

133-p
06:05.140 --> 06:07.900
AV1编码只受Chrome支持 在Edge中没有启用

134
06:07.900 --> 06:08.970
尽管它们几乎共享相同的代码库

136-p
06:11.980 --> 06:14.970
支持10比特通道的VP9配置文件只受Chrome支持

137
06:14.970 --> 06:15.990
而且只支持

138
06:15.990 --> 06:17.370
在接收端

139
06:17.370 --> 06:19.713
它在Safari中仍处于试验性阶段

140-p
06:22.988 --> 06:23.821
playoutdelayhint是一个可选的扩展

141
06:23.821 --> 06:25.317
它也只受Chrome支持

142-p
06:26.960 --> 06:30.410
另一个例子是abs-capture-time

144
06:30.410 --> 06:34.370
它是一个头信息扩展 可用于

145
06:34.370 --> 06:37.580
同步视频与标准元数据 只受Chrome支持

146
06:37.580 --> 06:39.240
但它也是隐藏的

147
06:39.240 --> 06:42.180
需要SDP修改来启用它

148-p
06:42.180 --> 06:45.850
最后再举一个例子 作为专业级功能的

150
06:46.683 --> 06:50.597
视频alpha通道被认为无法用于WebRTC

151
06:50.597 --> 06:54.960
WebRTC也没有预想过支持这一功能

152
06:54.960 --> 06:57.940
但在WebCodecs中

153
06:57.940 --> 06:59.520
正在考虑实现它

slide-16
06:59.520 --> 07:02.400
总的来说 现今的WebRTC是可用的

155
07:02.400 --> 07:03.770
我想说的是 即使它是

156
07:03.770 --> 07:06.420
以最低延迟传输专业广播质量媒体的最佳选择

157
07:06.420 --> 07:09.330
但为了能够使WebRTC成型

158
07:09.330 --> 07:11.690
我们仍有很多工作要做

159
07:11.690 --> 07:13.280
任重而道远

slide-17
07:13.280 --> 07:15.323
但好消息是 我们已经着手在做了
