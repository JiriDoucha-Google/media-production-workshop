WEBVTT FILE

1
00:07.200 --> 00:10.360
欢迎来到我的演讲 “在web架构中为机器学习

2
00:10.360 --> 00:13.240
审查OpenEXR成品文件”

3
00:13.240 --> 00:15.680
我是Max Grosse 是来自迪士尼研究所的

4
00:15.680 --> 00:17.480
首席软件工程师

6-p
00:17.480 --> 00:18.960
我将为各位展示我们采用的

7
00:18.960 --> 00:20.800
在机器学习方面的工作流程

8
00:20.800 --> 00:23.160
以及处理电影成品资源

9
00:23.160 --> 00:24.960
在这方面所提出的独特挑战

10
00:24.960 --> 00:29.800
以及我们如何利用现代web技术解决这个问题

slide-2
00:29.840 --> 00:31.480
由于我们部门隶属于

13
00:31.480 --> 00:33.280
华特迪士尼公司工作室

14
00:33.280 --> 00:35.120
我们自然要处理成品资源

15-p
00:35.120 --> 00:36.760
当涉及到图像时 这通常意味着

16
00:36.760 --> 00:38.320
我们要处理更高的分辨率

17
00:38.320 --> 00:41.800
最低1080p 最高4K甚至更高

18
00:41.800 --> 00:44.000
此外 成品图像通常

19
00:44.000 --> 00:45.800
具有高动态范围

20
00:45.800 --> 00:48.720
以16位或32位浮点的OpenEXR文件格式

21
00:48.720 --> 00:50.720
进行存储

23-p
00:50.720 --> 00:52.480
对许多应用来说

24
00:52.480 --> 00:54.600
除了最终组成的色彩数据外

25
00:54.600 --> 00:57.400
我们还需要检查图像的其他方面

26
00:57.400 --> 00:58.960
其中可能包括来自渲染的特征缓冲区

27
00:58.960 --> 01:01.480
如颜色深度 法线或透明度蒙版

28
01:01.480 --> 01:03.960
并作为单独的输入提供 这样你就可以

29
01:03.960 --> 01:06.360
快速确定每个最终的颜色像素

30
01:06.360 --> 01:08.640
所具有的深度或法线

31-p
01:08.640 --> 01:11.920
为了检查输入

33
01:11.920 --> 01:14.440
深度神经网络的训练数据

34
01:14.440 --> 01:17.120
以查看验证的误差图

35
01:17.120 --> 01:19.280
并大致能够判断

36
01:19.280 --> 01:21.400
成品结果的图像质量

37
01:21.400 --> 01:24.280
或者能让美术指导做出正确判断

38
01:24.280 --> 01:25.920
比起像Tensorboard中的

39
01:25.920 --> 01:28.200
jpeg图像的裁剪缩略图

40
01:28.200 --> 01:30.400
我们需要更多一点细节

slide-3
01:31.200 --> 01:35.720
我们的作品样例之一

43
01:35.720 --> 01:37.960
是我的同事在2017年

44
01:37.960 --> 01:40.360
美国计算机协会计算机图形专业大会上发表的

45
01:40.360 --> 01:42.800
用于蒙特卡洛渲染去噪的核预测卷积神经网络

47-p
01:43.640 --> 01:46.120
其中介绍了一种深度学习方法

48
01:46.120 --> 01:48.800
用于对蒙特卡洛渲染的图像进行去噪

49
01:48.800 --> 01:51.200
产出符合成品标准的高质量结果

slide-4
01:52.560 --> 01:54.400
于是我们展开了对JERI的研究

52
01:54.400 --> 01:56.920
即JavaScript扩展范围图像查看器

54-p
01:56.920 --> 02:00.760
我们的想法是建立一个远程

55
02:00.760 --> 02:03.600
或本地的HTTP服务器 不仅能够直接

56
02:03.600 --> 02:06.880
为我们提供所需要的OpenEXR图像

57
02:06.880 --> 02:09.640
而且还提供一个基于HTML5的查看器

58
02:09.640 --> 02:11.640
这样一来就可以在现代浏览器中

59
02:11.640 --> 02:15.800
直接审查这些OpenEXR图像

61-p
02:15.800 --> 02:16.920
尤其是我们可以方便地审查

62
02:16.920 --> 02:19.400
存储在我们的计算集群上的结果图像

63
02:19.400 --> 02:20.880
而不需要特地复制到本地

64
02:20.880 --> 02:22.960
或者挂载至本地

66-p
02:23.480 --> 02:25.320
这也保证了客户端

67
02:25.320 --> 02:26.880
接收的是原始图像

68
02:26.880 --> 02:28.520
没有任何额外的压缩

69
02:28.520 --> 02:30.600
因此能完全控制显示在浏览器中的

70
02:30.600 --> 02:32.760
图像的精确像素值

72
02:33.160 --> 02:34.680
它的功能就像一个可配置的标签

73
02:34.680 --> 02:37.800
有很多额外的功能

74
02:37.800 --> 02:39.720
来深入挖掘扩展范围的图像

slide-5
02:41.920 --> 02:43.880
为此 我们使用了EMScripten

77
02:43.880 --> 02:46.760
将OpenEXR库编译为WebAssembly

79-p
02:46.760 --> 02:49.120
EMScripten工具链在成熟度方面

80
02:49.120 --> 02:50.400
还有点欠缺

81
02:50.400 --> 02:52.240
所以要做好这个工作有点繁琐

82
02:52.240 --> 02:54.520
不过一旦完成

83
02:54.520 --> 02:55.880
它就有可能用于

84
02:55.880 --> 02:57.520
各种应用

86-p
02:57.520 --> 03:01.120
解码速度不是我们最关心的问题

87
03:01.120 --> 03:03.880
所以我们没有进行任何广泛的基准测试

88
03:03.880 --> 03:06.240
去研究与原生解决方案相比

89
03:06.240 --> 03:07.720
它对EXR图像的解码速度如何

90
03:07.720 --> 03:10.320
通常情况下 即使是在本地网络上

91
03:10.320 --> 03:12.120
我们在下载EXR时

92
03:12.120 --> 03:15.280
也会存在一些延迟 所以到目前为止

93
03:15.280 --> 03:17.720
解码速度对用户来说还算不上什么问题

95-p
03:18.600 --> 03:20.800
特别是在有一些本地缓存的情况下

96
03:20.800 --> 03:22.720
通常在切换加载图像时

97
03:22.720 --> 03:24.280
反正都是即时的

slide-6
03:26.400 --> 03:28.480
鉴于输入图像的扩展范围

100
03:28.480 --> 03:31.360
我们需要一种方法来控制

101
03:31.360 --> 03:33.880
诸如伽马值和曝光等参数 以备我们需要

102
03:33.880 --> 03:37.160
在特定的暗部或亮部区域调整细节

104-p
03:37.160 --> 03:41.640
深度学习通常是由损失函数驱动的

105
03:41.640 --> 03:44.240
这在我们的案例中通常是图像差异指标的组合

106
03:44.240 --> 03:47.320
将这一误差可视化

107
03:47.320 --> 03:48.920
对于帮助开发所需的模型

108
03:48.920 --> 03:50.400
具有重要意义

110-p
03:50.400 --> 03:53.320
针对所有这些可视化方面

111
03:53.320 --> 03:55.560
我们选择使用WebGL

112
03:55.560 --> 03:57.800
这是很自然的选择 它提供了

113
03:57.800 --> 03:59.600
一种非常有效和方便的方式

114
03:59.600 --> 04:03.400
来改变显示方式 而且不需要太多代码

115
04:03.400 --> 04:06.120
也不需要直接修改原始像素值

117-p
04:06.120 --> 04:09.400
特别是 这种方式把所有的像素操作

118
04:09.400 --> 04:11.800
交给了GPU 保持了用户体验的流畅性

119
04:11.800 --> 04:14.360
避免了在单个JavaScript线程中

120
04:14.360 --> 04:16.640
直接操作大型像素阵列

122-p
04:16.640 --> 04:21.800
基础的查看器应用主要是

123
04:21.800 --> 04:23.520
在TypeScript中用React.js编写的

124
04:23.520 --> 04:26.280
可以有选择地处理UI方面的问题

125
04:26.280 --> 04:28.680
且有利于将查看器集成到其他React.js项目中

slide-7
04:28.680 --> 04:32.880
查看器本身是通过一串JSON来配置的

128
04:32.880 --> 04:36.680
该串JSON描述了要加载哪些EXR图像

129
04:36.680 --> 04:39.960
查找这些图像的远程路径 哪些图像要分组

130
04:39.960 --> 04:43.000
以及哪些图像应该共同组成图像误差图

131
04:43.000 --> 04:44.800
（即图像差异）

slide-8
04:44.800 --> 04:51.640
下面是JERI查看器的一个简单演示

135-p
04:51.640 --> 04:54.920
这些例子都是来自JERI网站

136
04:54.920 --> 04:57.800
只是为了展示一下大概

137
04:57.800 --> 04:59.160
请注意 这些不是成品资源

138
04:59.160 --> 05:02.000
比我们的成品结果要差得多

139
05:02.000 --> 05:05.920
这里仅作展示用途

141-p
05:05.920 --> 05:09.840
在这个例子中 可见输入图像中存在噪点

142
05:09.840 --> 05:12.240
可能是来自于我们的渲染器

144-p
05:12.280 --> 05:14.880
我们现在可以切换到“优化”

145
05:14.880 --> 05:17.760
来检查简易去噪的结果

147-p
05:17.760 --> 05:23.680
然后 我们可以放大平移

148
05:23.680 --> 05:30.920
在像素层面来比较差异

150-p
05:30.960 --> 05:39.840
我们最终的目的

151
05:39.840 --> 05:41.480
是为了与真实场景

152
05:41.480 --> 05:43.960
或基准进行比较 这里也可以做到

153
05:43.960 --> 05:48.320
我们也可以直接切换到这一结果

155-p
05:48.320 --> 05:50.360
例如你可以看到

156
05:50.360 --> 05:52.800
冰块的细节丢失了不少

158-p
05:52.800 --> 05:53.800
更好的做法是 在输出和基准之间

159
05:53.800 --> 05:56.800
实时显示一个计算误差图

160
05:56.800 --> 05:59.600
就像你现在看到的这张图

162-p
05:59.600 --> 06:02.200
我们也可以在这里调整曝光值

163
06:02.200 --> 06:04.120
这样我们就可以更好地观察到

164
06:04.120 --> 06:06.920
我们本来看不到的细节部分

166-p
06:06.920 --> 06:12.280
当然 曝光调整对彩色图像

167
06:12.280 --> 06:14.280
也有同样的作用

169-p
06:14.280 --> 06:19.720
如果想观察它在不同的输入图像上的表现

170
06:19.720 --> 06:22.680
我们可以对不同的图像集重复上述做法

slide-9
06:22.680 --> 06:29.400
我们已经将它整合到机器学习监测系统中

173
06:29.400 --> 06:31.160
该系统正在我们的集群上运行

175-p
06:31.200 --> 06:33.320
这里是一个更典型的使用案例

176
06:33.320 --> 06:35.400
你可以在左侧栏中看到训练运行记录

177
06:35.400 --> 06:37.160
以及在主界面上显示的

178
06:37.160 --> 06:39.600
许多不同的图像集和指标

179
06:39.600 --> 06:41.680
这样就可以快速

180
06:41.680 --> 06:44.280
挖掘和监测你的进展和结果

182-p
06:44.280 --> 06:47.600
例如 我们可以查看不同的验证图像

183
06:47.600 --> 06:49.920
不同的通道集

184
06:49.920 --> 06:52.400
以及训练期间的不同时间点

185
06:52.400 --> 06:55.320
我们也可以随时启动Tensorboard

186
06:55.320 --> 06:57.640
来查看其他的记录指标

187
06:57.640 --> 07:00.640
或者输出一份结果报告 因此

188
07:00.640 --> 07:03.280
像JERI这样基于web的解决方案很合适

slide-10
07:03.320 --> 07:09.240
我们已经将JERI作为开源软件发布

191
07:09.240 --> 07:12.400
你可以自己试一下 将其整合至

192
07:12.400 --> 07:16.360
自己的解决方案中 详情可访问jeri.io

slide-11
07:16.360 --> 07:20.800
我要介绍的就是这些

195
07:20.800 --> 07:25.400
感谢大家聆听
