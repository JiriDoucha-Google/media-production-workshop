WEBVTT

1
00:06.580 --> 00:08.880
<v ->所以，你想在Web上看视频。</v>

2
00:08.880 --> 00:11.330
有很多相关的API和协议

3
00:11.330 --> 00:14.490
使移动的图像和声音能够在你的浏览器上呈现

4
00:14.490 --> 00:16.750
当然，他们中有些有超高延迟

5
00:16.750 --> 00:17.800
以及超高压缩

6
00:17.800 --> 00:19.510
其他也有一些超低压缩

7
00:19.510 --> 00:21.380
以及超低延迟

8
00:21.380 --> 00:23.900
但总的来说，你可以选择一个操作点

9
00:23.900 --> 00:27.300
并找到足够的工具，为你完成90%至100%的

10
00:27.300 --> 00:28.303
的工作

11-p
00:29.220 --> 00:31.410
现在，你决定走另一条路

12
00:31.410 --> 00:33.550
你想要摄取一些视频

13
00:33.550 --> 00:36.500
也有很多API和协议

14
00:36.500 --> 00:37.710
能够帮你

15
00:37.710 --> 00:40.360
改变压缩比和延迟

16
00:40.360 --> 00:42.21
以及质量和可靠性

17
00:42.210 --> 00:45.100
以及速度和实时性

18
00:45.100 --> 00:47.680
以及其他你需要的事情

19
00:47.680 --> 00:49.390
来实现视频摄取

20
00:49.390 --> 00:52.180
虽然没那么丝滑，但是能用。

21-p
00:52.180 --> 00:54.770
现在，你想要添加一些生产过程中的元数据 

22
00:54.770 --> 00:58.280
将其摄取到你的云生产系统中

23
00:58.280 --> 01:02.300
我通常将这种元数据归类为“外来物”，

24
01:02.300 --> 01:04.410
因为有很多不同的种类

25
01:04.410 --> 01:07.370
每种类型都有很小的用途

26
01:07.370 --> 01:11.500
真正好的基础设施很少

27
01:11.500 --> 01:14.400
解决一般情况的框架也很少

28
01:14.400 --> 01:16.550
我看过Arduino和Raspberry Pi的混合

29
01:16.550 --> 01:20.400
通过WiFi的RTP实现馈送，可以自定义速率控制

30
01:20.400 --> 01:22.250
支持不同的文件类型

31
01:22.250 --> 01:24.900
支持不同的时间方式

32
01:24.900 --> 01:27.310
不同的同步方式，不同的错误修正

33
01:27.310 --> 01:30.377
但是，同样的问题还是存在

34-p
01:30.377 --> 01:34.700
我想得到元数据

35
01:34.700 --> 01:37.440
在时间轴上，在我的视频和音频上

36
01:37.440 --> 01:40.160
当我拍摄的时候，我想要能够知道

37
01:40.160 --> 01:42.130
哪些元数据，是从哪些设备上来的

38
01:42.130 --> 01:45.110
是哪一次拍摄的

39
01:45.110 --> 01:47.730
用哪个相机拍摄的，在拍摄过程中

40
01:47.730 --> 01:49.100
很简单吧？

41-p
01:49.100 --> 01:51.000
这都不是新问题

42
01:51.000 --> 01:53.550
我们已经将这些类型的系统捆绑在一起

43
01:53.550 --> 01:56.380
从电影和电视的早期开始

44
01:56.380 --> 01:58.930
已经发生的改变是，我们现在有能力

45
01:58.930 --> 02:02.910
将大量的数据拉入公共云存储

46
02:02.910 --> 02:06.940
使用尽可能多的计算，尽可能多的...

47
02:06.940 --> 02:10.200
那些你能负担得起的云计算服务

48
02:10.200 --> 02:12.830
Arri, Nablet和TrackMen的了不起的人们

49
02:12.830 --> 02:15.460
帮助整理了一些工具来探索

50
02:15.460 --> 02:18.750
一些通用的解决方案，我们也记录这些工作

51
02:18.750 --> 02:22.800
在一个地址为mxf-live.io的网站上

52
02:22.800 --> 02:23.830
你可以看到我们捕获了一些数据

53
02:23.830 --> 02:26.700
从Arri相机的内部

54
02:26.700 --> 02:28.350
以及外部数据馈送

55
02:28.350 --> 02:31.210
用三脚架头部的云台、水平仪和摇柄

56
02:31.210 --> 02:34.140
将其封装为标准文件格式

57
02:34.140 --> 02:36.160
我们把它通过WiFi传送

58
02:36.160 --> 02:38.770
然后把它序列化到编辑的时间线上

59
02:38.770 --> 02:41.340
这样我们就可以在现场进行后期制作

60
02:41.340 --> 02:42.790
利用捕获的这些元数据

61
02:42.790 --> 02:44.670
太棒了！搞定了！

62-p
02:44.670 --> 02:45.503
其实还没有

63
02:45.503 --> 02:47.270
我们发现其实这里有

64
02:47.270 --> 02:51.340
4种主要的元数据，可以分为两个轴

65
02:51.340 --> 02:53.210
第一个轴很简单

66
02:53.210 --> 02:55.220
是二进制的，还是文本的？

67
02:55.220 --> 02:56.870
这很重要

68
02:56.870 --> 02:59.290
因为这能够很好的预测你将如何处理

69
02:59.290 --> 03:01.320
下游的元数据

70
03:01.320 --> 03:04.340
第二个轴是数据等时的位置

71
03:04.340 --> 03:06.820
换句话说，每个时钟滴答声对应一个样本

72
03:06.820 --> 03:08.700
每个时钟滴答声

73
03:08.700 --> 03:10.780
都有一个嵌入的定时?

74-p
03:10.780 --> 03:13.100
咱们把每一个象限里的

75
03:13.100 --> 03:15.224
元数据的例子都看一下

76
03:15.224 --> 03:17.170
定时二进制是很常见的

77
03:17.170 --> 03:19.100
你会发现

78
03:19.100 --> 03:20.390
镜头的位置

79
03:20.390 --> 03:22.980
对压电马达的每一个声音进行采样

80
03:22.980 --> 03:25.287
或者对每一帧进行采样

81
03:25.287 --> 03:28.000
等时文本

82
03:28.000 --> 03:31.800
可能是所有Dolby Vision高动态范围元数据属性

83
03:31.800 --> 03:34.740
视频每一帧都存储为XML文档

84
03:34.740 --> 03:38.500
二进制数据块，这可能是一个事件跟踪

85
03:38.500 --> 03:40.620
记录哪一台烟雾机被打开了

86
03:40.620 --> 03:42.850
是什么时候打开的

87
03:42.850 --> 03:45.900
文本数据，这是很常见的

88
03:45.900 --> 03:48.140
这就是封闭字幕

89
03:48.140 --> 03:50.340
其中文本的每个短语都有标签

90
03:50.340 --> 03:53.400
也带有该短语的时间信息

91-p
03:53.400 --> 03:55.600
一旦你掌握了这四种基本类型

92
03:55.600 --> 03:57.650
你可以看一下传输

93
03:57.650 --> 03:59.950
它有助于存储这些定时数据

94
03:59.950 --> 04:02.440
作为可序列化的数据包流

95
04:02.440 --> 04:03.770
因此我们选择MXF

96
04:03.770 --> 04:05.670
主要是考虑现有的基础设施

97
04:05.670 --> 04:08.980
以及将时钟表示为有理数的能力

98
04:08.980 --> 04:11.170
以便保持精确的计时

99
04:11.170 --> 04:13.740
如果系统保持运行，则无位移风险

100
04:13.740 --> 04:15.100
在很长一段时间内

101
04:15.100 --> 04:16.710
例如几周，几个月，以及几年

102
04:17.820 --> 04:20.330
然后可以映射和分层这些数据包

103
04:20.330 --> 04:22.800
用不同的方式传输，例如WebRTC

104
04:22.800 --> 04:26.890
把他们从现在的地方传输到需要的地方

105-p
04:26.890 --> 04:29.600
现在，要开始变得有趣了

106
04:29.600 --> 04:32.150
MXF对于硬件来说非常方便

107
04:32.150 --> 04:35.500
对固件也很方便，有很多开源项目

108
04:35.500 --> 04:38.640
例如Pixar的OpenTimelineIO和ASWS

109
04:38.640 --> 04:40.680
对互动来说更友好

110
04:40.680 --> 04:44.730
以通用的、独立于产品的方式使用这些数据

111
04:44.730 --> 04:48.380
话虽如此，我们知道转码视频是有损的

112
04:48.380 --> 04:51.700
而转码元数据实际上可能会破坏 

113
04:51.700 --> 04:52.510
它的有用性

114
04:52.510 --> 04:55.590
所以，要尽可能的保持原始数据

115
04:55.590 --> 04:59.770
可能体积庞大，但是原始形式的元数据至关重要

116
04:59.770 --> 05:02.960
计算元数据的简化代理

117
05:02.960 --> 05:05.660
对于可视化非常重要

118
05:05.660 --> 05:08.11
如果你打算在一般情况下做所有这些

119
05:08.110 --> 05:11.500
然后管理元数据类型的标识符

120
05:11.500 --> 05:13.650
以及它如何与其他值相关联

121
05:13.650 --> 05:15.71
可能成为一场复杂的噩梦

122
05:15.710 --> 05:18.100
除非你设计了某种通用框架

123
05:18.100 --> 05:21.350
为关联元素，基于简单标识符

124
05:21.350 --> 05:22.823
例如URI

125-p
05:23.770 --> 05:25.890
这就是目前我们所能做到的

126
05:25.890 --> 05:28.210
制片商和供应商对此感兴趣

127
05:28.210 --> 05:29.160
还有很多人也有兴趣

128
05:29.160 --> 05:31.430
我个人也希望能投入更多时间在这项工作上

129
05:31.430 --> 05:34.440
我将把我作为SMPTE标准副总裁的职位

130
05:34.440 --> 05:35.910
在一月份移交给其他人

131
05:35.910 --> 05:38.500
如果你有兴趣，我愿意和你深入交流

132
05:38.500 --> 05:41.910
我相信W3C的智囊团

133
05:41.910 --> 05:44.860
和SMPTE能够为视频的世界和其他行业

134
05:44.860 --> 05:48.187
真正创造出有用的东西

135
05:48.187 --> 05:49.200
谢谢！
